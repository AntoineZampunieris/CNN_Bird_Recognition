{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "PyTorch CUDA version: 12.6\n",
      "GPU: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Check the CUDA version used by PyTorch\n",
    "print(\"PyTorch CUDA version:\", torch.version.cuda)\n",
    "\n",
    "# Check the installed GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def load_images_from_directory(directory, target_size=(1024, 1024)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        if os.path.isdir(label_dir):\n",
    "            for img_name in os.listdir(label_dir):\n",
    "                img_path = os.path.join(label_dir, img_name)\n",
    "                img = image.load_img(img_path, target_size=target_size)\n",
    "                img_array = image.img_to_array(img)\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Load all images and labels\n",
    "all_images, all_labels = load_images_from_directory(r\"C:\\Users\\antoi\\Documents\\Nell_Antoine_Project\\DATA\")\n",
    "\n",
    "# Split into training and validation datasets\n",
    "train_images, validation_images, train_labels, validation_labels = train_test_split(\n",
    "    all_images, all_labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2272, 1024, 1024, 3)\n",
      "(2272,)\n",
      "(569, 1024, 1024, 3)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "validation_images = np.array(validation_images)\n",
    "validation_labels = np.array(validation_labels)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(validation_images.shape)\n",
    "print(validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collared_Dove' 'Wren' 'Starling' 'Collared_Dove' 'Long_Tailed_Tit']\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNModel(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv7): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=36864, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=20, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv7): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=36864, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size=3)\n",
    "        self.conv7 = nn.Conv2d(512, 1024, kernel_size=3)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout with 50% probability\n",
    "        \n",
    "        # Use a dummy input to calculate the size\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 1024, 1024)  # Batch size 1\n",
    "            x = self.pool(F.relu(self.conv1(dummy_input)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = self.pool(F.relu(self.conv3(x)))\n",
    "            x = self.pool(F.relu(self.conv4(x)))\n",
    "            x = self.pool(F.relu(self.conv5(x)))\n",
    "            x = self.pool(F.relu(self.conv6(x)))\n",
    "            x = self.pool(F.relu(self.conv7(x)))\n",
    "            self.flatten_size = x.numel()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 20)  # Assuming 20 classes\n",
    "        # Use CrossEntropyLoss for multi-class classification\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.pool(F.relu(self.conv6(x)))\n",
    "        x = self.pool(F.relu(self.conv7(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # Apply dropout after fc1\n",
    "        x = self.dropout(F.relu(self.fc2(x)))  # Apply dropout after fc2\n",
    "        x = self.fc3(x)  # No softmax needed\n",
    "        return x\n",
    "\n",
    "# Example of model instantiation\n",
    "model = CNNModel()\n",
    "print(model)\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1       [-1, 16, 1022, 1022]             448\n",
      "         MaxPool2d-2         [-1, 16, 511, 511]               0\n",
      "            Conv2d-3         [-1, 32, 509, 509]           4,640\n",
      "         MaxPool2d-4         [-1, 32, 254, 254]               0\n",
      "            Conv2d-5         [-1, 64, 252, 252]          18,496\n",
      "         MaxPool2d-6         [-1, 64, 126, 126]               0\n",
      "            Conv2d-7        [-1, 128, 124, 124]          73,856\n",
      "         MaxPool2d-8          [-1, 128, 62, 62]               0\n",
      "            Conv2d-9          [-1, 256, 60, 60]         295,168\n",
      "        MaxPool2d-10          [-1, 256, 30, 30]               0\n",
      "           Conv2d-11          [-1, 512, 28, 28]       1,180,160\n",
      "        MaxPool2d-12          [-1, 512, 14, 14]               0\n",
      "           Conv2d-13         [-1, 1024, 12, 12]       4,719,616\n",
      "        MaxPool2d-14           [-1, 1024, 6, 6]               0\n",
      "          Flatten-15                [-1, 36864]               0\n",
      "           Linear-16                  [-1, 512]      18,874,880\n",
      "          Dropout-17                  [-1, 512]               0\n",
      "           Linear-18                  [-1, 256]         131,328\n",
      "          Dropout-19                  [-1, 256]               0\n",
      "           Linear-20                   [-1, 20]           5,140\n",
      "================================================================\n",
      "Total params: 25,303,732\n",
      "Trainable params: 25,303,732\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12.00\n",
      "Forward/backward pass size (MB): 310.22\n",
      "Params size (MB): 96.53\n",
      "Estimated Total Size (MB): 418.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # For classification tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "validation_labels_encoded = label_encoder.transform(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Normalize only when converting, avoid extra copies\n",
    "train_images_tensor = torch.from_numpy(train_images).float().div(255)\n",
    "train_labels_tensor = torch.from_numpy(train_labels_encoded).long()\n",
    "\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "validation_images_tensor = torch.from_numpy(validation_images).float().div(255)\n",
    "validation_labels_tensor = torch.from_numpy(validation_labels_encoded).long()\n",
    "\n",
    "validation_dataset = TensorDataset(validation_images_tensor, validation_labels_tensor)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 402.8092208848873\n",
      "Epoch 2/10, Loss: 2.9950731153219516\n",
      "Epoch 3/10, Loss: 2.9930918535716096\n",
      "Epoch 4/10, Loss: 2.992284482633564\n",
      "Epoch 5/10, Loss: 2.992149274114152\n",
      "Epoch 6/10, Loss: 2.9911839777315166\n",
      "Epoch 7/10, Loss: 2.9914019225348887\n",
      "Epoch 8/10, Loss: 2.99117413540961\n",
      "Epoch 9/10, Loss: 2.9913894139545065\n",
      "Epoch 10/10, Loss: 2.991161153350078\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_dataloader:\n",
    "        # Move data to GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Permute the dimensions of the input tensor\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_dataloader)}\")\n",
    "    #with torch.no_grad(): #doesn't interfere with training\n",
    "    #    print(model(torch.randn(1, 3, 100, 100).to(device)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 4.22%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradients for evaluation\n",
    "    for test_X, test_y in validation_dataloader:\n",
    "        # Move data to GPU\n",
    "        test_X, test_y = test_X.to(device), test_y.to(device)\n",
    "        \n",
    "        # Fix shape (if images are in (batch, H, W, C) format)\n",
    "        test_X = test_X.permute(0, 3, 1, 2)  \n",
    "\n",
    "        # Forward pass\n",
    "        test_outputs = model(test_X)\n",
    "        \n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(test_outputs, 1)  # Get the class with highest probability\n",
    "        \n",
    "        # Update total and correct predictions\n",
    "        correct += (predicted == test_y).sum().item()\n",
    "        total += test_y.size(0)\n",
    "\n",
    "# Compute final accuracy across all batches\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
