{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "PyTorch CUDA version: 12.6\n",
      "GPU: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Check the CUDA version used by PyTorch\n",
    "print(\"PyTorch CUDA version:\", torch.version.cuda)\n",
    "\n",
    "# Check the installed GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def load_images_from_directory(directory, target_size=(256, 256)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        if os.path.isdir(label_dir):\n",
    "            for img_name in os.listdir(label_dir):\n",
    "                img_path = os.path.join(label_dir, img_name)\n",
    "                img = image.load_img(img_path, target_size=target_size)\n",
    "                img_array = image.img_to_array(img)\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Load all images and labels\n",
    "all_images, all_labels = load_images_from_directory(r\"C:\\Users\\antoi\\Documents\\Nell_Antoine_Project\\DATA\")\n",
    "\n",
    "# Split into training and validation datasets\n",
    "train_images, validation_images, train_labels, validation_labels = train_test_split(\n",
    "    all_images, all_labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2272, 256, 256, 3)\n",
      "(2272,)\n",
      "(569, 256, 256, 3)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "validation_images = np.array(validation_images)\n",
    "validation_labels = np.array(validation_labels)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(validation_images.shape)\n",
    "print(validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 95.  84.  92.]\n",
      "  [ 96.  85.  91.]\n",
      "  [120. 109. 113.]\n",
      "  ...\n",
      "  [ 99. 131.  82.]\n",
      "  [109. 136.  93.]\n",
      "  [109. 136.  95.]]\n",
      "\n",
      " [[149. 135. 134.]\n",
      "  [150. 136. 136.]\n",
      "  [150. 136. 135.]\n",
      "  ...\n",
      "  [ 96. 129.  76.]\n",
      "  [104. 131.  86.]\n",
      "  [105. 132.  89.]]\n",
      "\n",
      " [[175. 163. 147.]\n",
      "  [174. 162. 150.]\n",
      "  [173. 160. 154.]\n",
      "  ...\n",
      "  [ 91. 124.  71.]\n",
      "  [ 98. 126.  78.]\n",
      "  [104. 131.  86.]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collared_Dove' 'Wren' 'Starling' 'Collared_Dove' 'Long_Tailed_Tit']\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.str_('Greenfinch'), np.str_('Song_Thrush'), np.str_('Coal_Tit'), np.str_('Long_Tailed_Tit'), np.str_('Collared_Dove'), np.str_('Blackbird'), np.str_('Bluetit'), np.str_('Starling'), np.str_('Robin'), np.str_('Chaffinch'), np.str_('House_Sparrow'), np.str_('Magpie'), np.str_('Dunnock'), np.str_('Wood_Pigeon'), np.str_('Carrion_Crow'), np.str_('Great_Tit'), np.str_('Feral_Pigeon'), np.str_('Wren'), np.str_('Goldfinch'), np.str_('Jackdaw')}\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(set(train_labels))\n",
    "print(len(set(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimplifiedCNNModel(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=115200, out_features=256, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=20, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimplifiedCNNModel(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=115200, out_features=256, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=256, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimplifiedCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimplifiedCNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #self.conv4 = nn.Conv2d(128, 256, kernel_size=3)  # New convolutional layer\n",
    "        #self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)  # New pooling layer\n",
    "        \n",
    "        # Use a dummy input to calculate the size\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 256, 256)  # Batch size 1\n",
    "            x = self.pool1(F.relu(self.conv1(dummy_input)))\n",
    "            x = self.pool2(F.relu(self.conv2(x)))\n",
    "            x = self.pool3(F.relu(self.conv3(x)))\n",
    "            #x = self.pool4(F.relu(self.conv4(x)))  # Pass through the new layer\n",
    "            self.flatten_size = x.numel()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 256)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Add dropout layer with 50% probability\n",
    "        self.fc2 = nn.Linear(256, 20)  # Assuming 20 classes\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        #x = self.pool4(F.relu(self.conv4(x)))  # Pass through the new layer\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc2(x)  # No softmax needed\n",
    "        return x\n",
    "\n",
    "# Example of model instantiation\n",
    "model = SimplifiedCNNModel()\n",
    "print(model)\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 254, 254]             896\n",
      "         MaxPool2d-2         [-1, 32, 127, 127]               0\n",
      "            Conv2d-3         [-1, 64, 125, 125]          18,496\n",
      "         MaxPool2d-4           [-1, 64, 62, 62]               0\n",
      "            Conv2d-5          [-1, 128, 60, 60]          73,856\n",
      "         MaxPool2d-6          [-1, 128, 30, 30]               0\n",
      "           Flatten-7               [-1, 115200]               0\n",
      "            Linear-8                  [-1, 256]      29,491,456\n",
      "           Dropout-9                  [-1, 256]               0\n",
      "           Linear-10                   [-1, 20]           5,140\n",
      "================================================================\n",
      "Total params: 29,589,844\n",
      "Trainable params: 29,589,844\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 34.47\n",
      "Params size (MB): 112.88\n",
      "Estimated Total Size (MB): 148.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # For classification tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0007)  # Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "validation_labels_encoded = label_encoder.transform(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [ 5 19 17  5 13]\n",
      "Encoded labels shape: (2272,)\n",
      "Validation labels shape: (569,)\n",
      "Number of classes: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoded labels:\", train_labels_encoded[:5])\n",
    "print(\"Encoded labels shape:\", train_labels_encoded.shape)\n",
    "print(\"Validation labels shape:\", validation_labels_encoded.shape)\n",
    "print(\"Number of classes:\", len(set(train_labels_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Permute if in HWC format (i.e., (N, H, W, C))\n",
    "if train_images.shape[-1] == 3:\n",
    "    train_images = train_images.transpose(0, 3, 1, 2)  # (N, H, W, C) → (N, C, H, W)\n",
    "    \n",
    "# Normalize only when converting, avoid extra copies\n",
    "train_images_tensor = torch.from_numpy(train_images).float().div(255)\n",
    "train_labels_tensor = torch.from_numpy(train_labels_encoded).long()\n",
    "\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "if validation_images.shape[-1] == 3:\n",
    "    validation_images = validation_images.transpose(0, 3, 1, 2)  # (N, H, W, C) → (N, C, H, W)\n",
    "\n",
    "validation_images_tensor = torch.from_numpy(validation_images).float().div(255)\n",
    "validation_labels_tensor = torch.from_numpy(validation_labels_encoded).long()\n",
    "\n",
    "validation_dataset = TensorDataset(validation_images_tensor, validation_labels_tensor)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training dataloader: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19)]\n",
      "Unique labels in validation dataloader: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19)]\n"
     ]
    }
   ],
   "source": [
    "# Collect unique labels from the training dataloader\n",
    "train_dataloader_labels = set()\n",
    "for _, labels in train_dataloader:\n",
    "    train_dataloader_labels.update(labels.numpy())\n",
    "\n",
    "print(\"Unique labels in training dataloader:\", sorted(train_dataloader_labels))\n",
    "\n",
    "# Collect unique labels from the validation dataloader\n",
    "validation_dataloader_labels = set()\n",
    "for _, labels in validation_dataloader:\n",
    "    validation_dataloader_labels.update(labels.numpy())\n",
    "\n",
    "print(\"Unique labels in validation dataloader:\", sorted(validation_dataloader_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs, labels = next(iter(train_dataloader))\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "for step in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Step {step}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([256, 3, 256, 256])\n",
      "Input min/max: tensor(0.) tensor(1.)\n",
      "Label shape: torch.Size([256])\n",
      "Label dtype: torch.int64\n",
      "Unique labels: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = next(iter(train_dataloader))\n",
    "print(\"Input shape:\", inputs.shape)          # should be (16, 3, 256, 256)\n",
    "print(\"Input min/max:\", inputs.min(), inputs.max())  # should be ~0–1\n",
    "print(\"Label shape:\", labels.shape)          # should be (16,)\n",
    "print(\"Label dtype:\", labels.dtype)          # should be torch.long\n",
    "print(\"Unique labels:\", torch.unique(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 4.630975749757555\n",
      "Epoch 2/25, Loss: 2.9525300661722818\n",
      "Epoch 3/25, Loss: 2.7732063399420843\n",
      "Epoch 4/25, Loss: 2.4554997285207114\n",
      "Epoch 5/25, Loss: 2.1296990977393255\n",
      "Epoch 6/25, Loss: 1.7675209045410156\n",
      "Epoch 7/25, Loss: 1.4756604300604925\n",
      "Epoch 8/25, Loss: 1.1667420996559992\n",
      "Epoch 9/25, Loss: 0.8817438019646539\n",
      "Epoch 10/25, Loss: 0.6986303726832072\n",
      "Epoch 11/25, Loss: 0.5613496171103584\n",
      "Epoch 12/25, Loss: 0.4042259057362874\n",
      "Epoch 13/25, Loss: 0.31756026877297294\n",
      "Epoch 14/25, Loss: 0.25861866606606376\n",
      "Epoch 15/25, Loss: 0.192703268594212\n",
      "Epoch 16/25, Loss: 0.15628764198886025\n",
      "Epoch 17/25, Loss: 0.14456101258595785\n",
      "Epoch 18/25, Loss: 0.12979380041360855\n",
      "Epoch 19/25, Loss: 0.13377374162276587\n",
      "Epoch 20/25, Loss: 0.10477032760779063\n",
      "Epoch 21/25, Loss: 0.08961563102073139\n",
      "Epoch 22/25, Loss: 0.08721682926019032\n",
      "Epoch 23/25, Loss: 0.08702624175283644\n",
      "Epoch 24/25, Loss: 0.0856590283413728\n",
      "Epoch 25/25, Loss: 0.07160089910030365\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_dataloader:\n",
    "        # Move data to GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_dataloader)}\")\n",
    "    #with torch.no_grad(): #doesn't interfere with training\n",
    "    #    print(model(torch.randn(1, 3, 100, 100).to(device)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample outputs: tensor([ 0.1387,  0.0215, -0.1125, -0.0194,  0.0965,  0.0040,  0.1223, -0.4186,\n",
      "         0.0743,  0.1042,  0.0977,  0.1231, -0.1692,  0.0762, -0.3756,  0.0763,\n",
      "         0.1036, -0.0341,  0.0636,  0.0942], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample outputs:\", outputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 47.63%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradients for evaluation\n",
    "    for test_X, test_y in validation_dataloader:\n",
    "        # Move data to GPU\n",
    "        test_X, test_y = test_X.to(device), test_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        test_outputs = model(test_X)\n",
    "        \n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(test_outputs, 1)  # Get the class with highest probability\n",
    "        \n",
    "        # Update total and correct predictions\n",
    "        correct += (predicted == test_y).sum().item()\n",
    "        total += test_y.size(0)\n",
    "\n",
    "# Compute final accuracy across all batches\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
